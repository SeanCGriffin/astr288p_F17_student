{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8: Model Fitting\n",
    "\n",
    "\n",
    "One of the most common things in scientific computing is model fitting. Numerical Recipes devotes a number of chapters to this.\n",
    "\n",
    "* Least squares fitting versus chisquare fitting\n",
    "* scipy \"curve_fit\"\n",
    "* Making out own fitter\n",
    "\n",
    "Later, we will also need to be able to read data, since we will try fitting real data and interpreting the results. We will be using an ascii file reader to parse real astronomical data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x, amplitude=1, mu=0, sig=1):\n",
    "    return amplitude * np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_width = 10\n",
    "\n",
    "n_points = 64\n",
    "\n",
    "time_axis = np.linspace(0,16,n_points,endpoint=False)\n",
    "fine_time_axis = np.linspace(time_axis[0], time_axis[-1], 10 * n_points, endpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amplitude = 120\n",
    "mean = 6.5\n",
    "width = 0.7\n",
    "\n",
    "noise = np.random.normal(0, noise_width, len(time_axis))\n",
    "pedestal = -30\n",
    "source = -1 * gauss(time_axis, amplitude, mean, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contaminated_pulse = source + noise + pedestal\n",
    "errors = np.ones(len(contaminated_pulse)) * 10\n",
    "\n",
    "for i in contaminated_pulse:\n",
    "    if i > 0:\n",
    "        i = -1 #setting to -1 and not to zero so as to not break some math later.\n",
    "#this line basically just checks that all of our data points are negative \n",
    "#it's basically saying \"our electronics can only measure signals in one direction\"\n",
    "\n",
    "\n",
    "plt.errorbar(time_axis, contaminated_pulse, errors,fmt='o')\n",
    "plt.xlabel(\"t (ns)\")\n",
    "plt.ylabel(\"v (mV)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing arguments this way allows you to pass an arbitrarily large number of arguments to a function. \n",
    "#for example: \n",
    "\n",
    "def foo(x, *args):\n",
    "    print(\"args:\")\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "        \n",
    "def foo2(x, **kwargs):\n",
    "    print(\"kwargs:\")\n",
    "    for key in kwargs.keys():\n",
    "        print(\"{0:s}: {1}\".format(key, kwargs[key]))\n",
    "    \n",
    "    \n",
    "def foo3(x, *args, **kwargs):\n",
    "    print(\"args:\")\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "    print(\"-----\")    \n",
    "    print(\"kwargs:\")\n",
    "    for key in kwargs.keys():\n",
    "        print(\"{0:s}: {1}\".format(key, kwargs[key]))\n",
    "        \n",
    "\n",
    "foo(time_axis, 10, 19, \"stealth\")       \n",
    "print()\n",
    "foo2(time_axis, a=10, b=12, name=\"stealth_bird\")\n",
    "print()\n",
    "foo3(time_axis, 10, 19, \"jupiter\", r=\"one_string\", g='a', something_else=\"some other string\", input_list=[12,13,190])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gauss(x, *args):\n",
    "\n",
    "    A, mu, sigma = args\n",
    "    return A*np.exp(-(x-mu)**2/(2.*sigma**2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#curve_fit is a powerful and commonly used fitter. \n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#p0 is the initial guess for the fitting coefficients (A, mu and sigma above, in that order)\n",
    "#for more complicated models and fits, the choice of initial conditions is also important \n",
    "#to ensuring that the fit will converge. We will see this later.\n",
    "\n",
    "param_names = [\"norm\", \"mean\", \"width\"]\n",
    "p0 = [contaminated_pulse.max(), 5., -1]\n",
    "\n",
    "coeff, cm = curve_fit(gauss, time_axis, contaminated_pulse, p0=p0, sigma=errors)\n",
    "coeff_error = np.sqrt(np.diag(cm))\n",
    "flux_fit = gauss(fine_time_axis, *coeff)\n",
    "for name, param,error in zip(param_names, coeff, coeff_error):\n",
    "    print(\"{0:8s}: {1:6.2f} +- {2:6.2f}\".format(name, param, error))\n",
    "\n",
    "fig,axes = plt.subplots(2,1, sharex=True, figsize=[8,6])\n",
    "axes[0].errorbar(time_axis, contaminated_pulse, errors, fmt='o')\n",
    "axes[0].plot(fine_time_axis, flux_fit,\"--\")\n",
    "\n",
    "residuals = contaminated_pulse - gauss(time_axis, *coeff)\n",
    "axes[1].errorbar(time_axis, residuals, errors, fmt='o')\n",
    "axes[1].plot(time_axis, np.zeros(len(time_axis)), '--')\n",
    "\n",
    "for a in axes:\n",
    "    a.set_xlabel(\"t (ns)\")\n",
    "axes[0].set_ylabel(\"V (mV)\")\n",
    "axes[1].set_ylabel(\"data - fit\")\n",
    "plt.show()\n",
    "plt.hist(residuals, bins=20)\n",
    "plt.xlabel(\"data-fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like our fit did a poor job, there is still a lot of structure in the residuals, and we can tell by eye that the fit simply didn't converge. \n",
    "\n",
    "One method of testing how good a fit is is the $\\chi^2$ test. It is basically a measure of the distance the data points are away from the fit. The simplest version (one without error bars) can be calculated as follows:\n",
    "\n",
    "$$ \\chi^2 = \\sum_{i} \\frac{(y_i - f(x_i))^2}{\\sigma_i^2}$$\n",
    "\n",
    "where $f(x)$ is your model (i.e. the function you are fitting), $x_i$ is the independent variable and $y_i$ and $\\sigma_i$ are are your measurements and their uncertainties.\n",
    "\n",
    "Generally, the number we want to quote is the \"chi-square per degrees of freedom\" ($\\chi^2 / NDF$), which takes into consideration the number of data points going into a fit. If you have more data points than you do paremeters in your model, in general you will produce a better fit. The number of degrees of freedom is calculated as\n",
    "\n",
    "$$ NDF = k - n_{p} $$\n",
    "\n",
    "where $n_{p}$ is the number of parameters in your fit. So, if we were fitting a straight line (2 parameters, slope and intercept) to a set of 10 measurements, we would have 8 degrees of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_chisquare(meas, sigma, fit):\n",
    "    \n",
    "    diff = pow(meas-fit, 2.)\n",
    "    test_statistic = (diff / pow(sigma,2.)).sum()\n",
    "    \n",
    "    return test_statistic\n",
    "    \n",
    "TS = calc_chisquare(contaminated_pulse, errors, gauss(time_axis, *coeff))\n",
    "NDF = len(contaminated_pulse) - len(coeff)\n",
    "print(\"chisquare/NDF = {0:.2f} / {1:d}  = {2:.2f}\".format(TS, NDF, TS / float(NDF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't a great $\\chi^2$ -- let's see if we can make it better. \n",
    "We expect a good fit to have a $\\chi^2 / NDF$ of about 1 -- this means that all data points lie within ~1 error bar of the fit vale.\n",
    "If a $\\chi^2/NDF$ value is too small, it usually means that our errorbars are too large; conversely if the errorbars are too small we can end up with a huge chisquare, so this must all be taken with a bit of a grain of salt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we are fitting a simple Gaussian, which doesn't account for the offset from zero away from the pulse -- this is because we have a **pedestal**, which can be thought of as what is seen by the electronics even when there is no signal. \n",
    "\n",
    "One way to handle this is to subtract off the pedestal, but how do we compute it? \n",
    "\n",
    "If we make sume assumptions (e.g. our signal arrives somwehre around the middle of our data) then we can calculate the pedestal and subtract it from our data, which should help the fit significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slice_condition = time_axis <= 4\n",
    "pedestal_area = time_axis[slice_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What's going on here? \n",
    "\n",
    "#We are selecting a view of time_axis where time_axis is <= 4;\n",
    "#this turns returns a truth table that we can use to slice out relevant data from our signal:\n",
    "print(slice_condition)\n",
    "print(pedestal_area)\n",
    "\n",
    "pedestal_values = contaminated_pulse[slice_condition]\n",
    "print(pedestal_values)\n",
    "\n",
    "plt.errorbar(time_axis[slice_condition], contaminated_pulse[slice_condition], errors[slice_condition], fmt='o')\n",
    "plt.xlabel(\"t (ns)\")\n",
    "plt.ylabel(\"V (mV)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can manually compute the mean pedestal, subtract it off of our data, and plot it:\n",
    "pedestal = pedestal_values.mean()\n",
    "print(\"Pedestal: {0:.2f}\".format(pedestal))\n",
    "ped_subtracted_pulse = contaminated_pulse - pedestal\n",
    "\n",
    "plt.errorbar(time_axis, ped_subtracted_pulse, errors, fmt=\"o\")\n",
    "plt.xlabel(\"t (ns)\")\n",
    "plt.ylabel(\"V (mV) (pedestal-subtracted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"norm\", \"mean\", \"width\"]\n",
    "p0 = [contaminated_pulse.min(), 7., 1.]\n",
    "\n",
    "coeff, cm = curve_fit(gauss, time_axis, ped_subtracted_pulse, p0=p0, sigma=errors)\n",
    "coeff_error = np.sqrt(np.diag(cm))\n",
    "flux_fit = gauss(time_axis, *coeff)\n",
    "for name, param,error in zip(param_names, coeff, coeff_error):\n",
    "    print(\"{0:8s}: {1:6.2f} +- {2:6.2f}\".format(name, param, error))\n",
    "\n",
    "fig,axes = plt.subplots(2,1, sharex=True, figsize=[8,6])\n",
    "axes[0].errorbar(time_axis, ped_subtracted_pulse, errors, fmt='.')\n",
    "axes[0].plot(time_axis, flux_fit,\"--\")\n",
    "\n",
    "residuals = ped_subtracted_pulse - flux_fit\n",
    "axes[1].errorbar(time_axis, residuals, errors, fmt='.')\n",
    "axes[1].plot(time_axis, np.zeros(len(time_axis)), '--')\n",
    "\n",
    "for a in axes:\n",
    "    a.set_xlabel(\"t (ns)\")\n",
    "axes[0].set_ylabel(\"V (mV)\")\n",
    "axes[1].set_ylabel(\"data - fit\")\n",
    "\n",
    "plt.show()\n",
    "plt.hist(residuals, bins=10)\n",
    "plt.xlabel(\"data-fit\")\n",
    "plt.show()\n",
    "\n",
    "TS = calc_chisquare(ped_subtracted_pulse, errors, gauss(time_axis, *coeff))\n",
    "NDF = len(ped_subtracted_pulse) - len(coeff)\n",
    "print(\"chisquare/NDF = {0:.2f} / {1:d}  = {2:.2f}\".format(TS, NDF, TS / float(NDF)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We have a good fit now; there doesn't appear to be anything in the residuals but random noise centered at zero. We could even fit that distribution and determine how well it is fitted by a Gaussian, which would give us a measure of how random our noise is (e.g. the noise could be **correlated** noise, which is very difficult to handle in experiments). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively to calculating the pedestal, we can try to include it in our model of the signal. To do this, we will change our fit function to include a parameter which is the pedestal. This is often the way things are done, since you usually don't have *a priori* information about your signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_with_pedestal(x, *p):\n",
    "    '''\n",
    "    This is a Gaussian fit with a pedestal. \n",
    "    '''\n",
    "    return gauss(x, *p[0:3]) + p[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"norm\", \"mean\", \"width\", \"pedestal\"]\n",
    "p0 = [contaminated_pulse.min(), 6., 1., -10]\n",
    "\n",
    "coeff, cm = curve_fit(gaussian_with_pedestal, time_axis, contaminated_pulse, p0=p0, sigma=errors)\n",
    "coeff_error = np.sqrt(np.diag(cm))\n",
    "flux_fit = gaussian_with_pedestal(time_axis, *coeff)\n",
    "for name, param,error in zip(param_names, coeff, coeff_error):\n",
    "    print(\"{0:8s}: {1:6.2f} +- {2:6.2f}\".format(name, param, error))\n",
    "\n",
    "fig,axes = plt.subplots(2,1, sharex=True, figsize=[8,6])\n",
    "axes[0].errorbar(time_axis, contaminated_pulse, errors, fmt='.')\n",
    "axes[0].plot(time_axis, flux_fit,\"--\")\n",
    "\n",
    "residuals = contaminated_pulse - flux_fit\n",
    "axes[1].errorbar(time_axis, residuals, errors, fmt='o')\n",
    "axes[1].plot(time_axis, np.zeros(len(time_axis)), '--')\n",
    "\n",
    "for a in axes:\n",
    "    a.set_xlabel(\"t (ns)\")\n",
    "axes[0].set_ylabel(\"V (mV)\")\n",
    "axes[1].set_ylabel(\"data - fit\")\n",
    "\n",
    "plt.show()\n",
    "plt.hist(residuals, bins=10)\n",
    "plt.xlabel(\"data-fit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can plot this alongside the ACTUAL gaussian signal we generated and see how closely the fit \n",
    "## matches the real thing.\n",
    "\n",
    "true_data = -gauss(time_axis, amplitude, mean, width) + pedestal\n",
    "\n",
    "fig,axes = plt.subplots(2,1, sharex=True, figsize=[8,6])\n",
    "axes[0].errorbar(time_axis, contaminated_pulse, errors, fmt='.')\n",
    "axes[0].plot(time_axis, flux_fit,\"g--\", label=\"Fit\")\n",
    "axes[0].plot(time_axis, true_data, 'r--', label=\"True\")\n",
    "axes[0].legend()\n",
    "residuals = contaminated_pulse - flux_fit\n",
    "axes[1].errorbar(time_axis, residuals, errors, fmt='go')\n",
    "residuals = contaminated_pulse - true_data\n",
    "axes[1].errorbar(time_axis, residuals, errors, fmt='ro')\n",
    "axes[1].plot(time_axis, np.zeros(len(time_axis)), '--')\n",
    "\n",
    "for a in axes:\n",
    "    a.set_xlabel(\"t (ns)\")\n",
    "axes[0].set_ylabel(\"V (mV)\")\n",
    "axes[1].set_ylabel(\"data - fit\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.hist(contaminated_pulse - flux_fit, bins=20, label=\"Fit\", alpha=0.25)\n",
    "plt.hist(contaminated_pulse - true_data, bins=20, label=\"True\", alpha=0.25)\n",
    "plt.legend()\n",
    "plt.xlabel(\"data-fit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next example, we have some continum emission and three spectral lines (which we are assuming are Gaussian in shape). \n",
    "\n",
    "In-class exercise: We will write our own *simple* fitter which will ignore uncertainties on measurements. The simplest way to do this is to do a least-squares fit. \n",
    "\n",
    "We will use the **scipy.optimize** libraries and minimize() function. \n",
    "\n",
    "You will want to define a function that you want to minimize, your so-called 'loss function', which is basically just a residuals calculation. You want to minimize your *mean squared* residual. \n",
    "\n",
    "Compare your result to the optimize.leastsq() function!\n",
    "\n",
    "The examples below are **incomplete**; we will likely split this into two different notebooks and discuss getting good parameter estimates to use as our initial guess, since it is very important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x,*params):\n",
    "    a,b = params\n",
    "    return a*x + b\n",
    "\n",
    "energy = np.linspace(10,100,100)\n",
    "spectral_line1 = gauss(energy, *[50, 42.1, 3])\n",
    "spectral_line2 = gauss(energy, *[100, 68.7, 1])\n",
    "spectral_line3 = gauss(energy, *[100, 18.1, 0.5])\n",
    "counts = linear(energy,-3,500) + spectral_line1 + spectral_line2 + spectral_line3 + np.random.normal(0, 3, size=len(energy)) \n",
    "\n",
    "#for this example, we will say that the errors on our measurements have to do with the counting errors\n",
    "#So we will use Poissonian statistics here:\n",
    "errors = np.sqrt(counts)\n",
    "#Note that this assumes that the response of the detector is uniform across all energies; in reality this is not the case; \n",
    "#These would get tied up in **systematic** uncertainties and the instrument response function. \n",
    "#We'll touch on this another time.\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.errorbar(energy,counts,errors, fmt='.')\n",
    "plt.xlabel(\"energy (GeV)\")\n",
    "plt.ylabel(\"flux (counts)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as sciopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals(parameters, data_x, data_y, model):\n",
    "    '''\n",
    "    Returns the residuals of a model vs data.\n",
    "    '''\n",
    "    return data_y - model(data_x, *parameters)\n",
    "\n",
    "## Test using scipy.optimize.leastsq on a dummy fitting case.\n",
    "data_x = np.array([0,1,2,3,4])\n",
    "data_y = 5 * data_x + 3 + np.random.normal(0,0.5, size=len(data_x))\n",
    "\n",
    "model = linear\n",
    "\n",
    "coeff, _ = sciopt.leastsq(residuals,[0.1, 1], args=(data_x, data_y, model))\n",
    "plt.plot(data_x,data_y, 'o')\n",
    "fit_x = np.linspace(data_x[0], data_x[-1])\n",
    "plt.plot(fit_x, model(fit_x, *coeff), '--')\n",
    "plt.show()\n",
    "\n",
    "print(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(parameters, data_x, data_y, model, verbose=False):\n",
    "    '''\n",
    "    This is a really generic loss function. \n",
    "    It can take in any number of parameters, any generic model.\n",
    "    \n",
    "    Notice that the parameters are passed *first*.\n",
    "    This is because of the way scipy's libraries need the function to be formatted.\n",
    "    '''\n",
    "    \n",
    "    loss = pow(residuals(parameters, data_x, data_y, model), 2.).sum()\n",
    "    if verbose:\n",
    "        print(loss)\n",
    "    return loss\n",
    "\n",
    "guess = np.array([50. , 312.])\n",
    "sciopt.minimize(loss_function, guess, args=(data_x, data_y, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_model(x, *params):\n",
    "    return linear(x, *params[0:2]) + gauss(x, *params[2:5]) + gauss(x, *params[5:8]) + gauss(x, *params[8:11])\n",
    "\n",
    "\n",
    "guess = np.array([-10, 500, 200, 20, 3, 200, 40, 3, 200, 68, 3], dtype=float)\n",
    "\n",
    "fit_energy=np.linspace(energy[0], energy[-1], len(energy)*100)\n",
    "coeff, cov = sciopt.curve_fit(custom_model, energy, counts, p0=guess, sigma=errors)\n",
    "coeff_error = np.sqrt(np.diag(cov))\n",
    "param_names = [\"Continuum slope\", \"continuum intercept\", \n",
    "               \"peak0_A\", \"peak0_mu\", \"peak0_sigma\", \n",
    "               \"peak1_A\", \"peak1_mu\", \"peak1_sigma\",\n",
    "               \"peak2_A\", \"peak2_mu\", \"peak2_sigma\"]\n",
    "\n",
    "for name, param,error in zip(param_names, coeff, coeff_error):\n",
    "    print(\"{0:30s}: {1:6.2f} +- {2:6.2f}\".format(name, param, error))\n",
    "    \n",
    "plt.figure(figsize=[8,6])\n",
    "plt.errorbar(energy,counts,errors, fmt='.')\n",
    "plt.xlabel(\"energy (GeV)\")\n",
    "plt.ylabel(\"flux (counts)\")\n",
    "plt.plot(fit_energy, custom_model(fit_energy, *coeff))\n",
    "plt.show()\n",
    "\n",
    "TS = calc_chisquare(counts, errors, custom_model(energy, *coeff))\n",
    "NDF = len(contaminated_pulse) - len(coeff)\n",
    "print(\"chisquare/NDF = {0:.2f} / {1:d}  = {2:.2f}\".format(TS, NDF, TS / float(NDF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = sciopt.minimize(loss_function, guess, args=(energy, counts, custom_model, False))\n",
    "my_coeff = res.x\n",
    "plt.errorbar(energy, counts, errors, fmt='.')\n",
    "plt.plot(energy, custom_model(energy, *my_coeff))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for name, param in zip(param_names, my_coeff):\n",
    "    print(\"{0:30s}: {1:6.2f}\".format(name, param))\n",
    "    \n",
    "\n",
    "TS = calc_chisquare(counts, errors, custom_model(energy, *my_coeff))\n",
    "NDF = len(counts) - len(my_coeff)\n",
    "print(\"chisquare/NDF = {0:.2f} / {1:d}  = {2:.2f}\".format(TS, NDF, TS / float(NDF)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
